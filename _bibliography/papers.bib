---
---

@string{aps = {American Physical Society,}}

@inproceedings{marouf2025ask,
  title={Ask and Remember: A Questions-Only Replay Strategy for Continual Visual Question Answering},
  author={Marouf, Imad Eddine and Tartaglione, Enzo and Lathuiliere, Stephane and van de Weijer, Joost},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
  year={2025},
  abbr={ICCV},
  arxiv={2502.04469},
  code={https://github.com/IemProg/QUAD},
  abstract={Continual Learning in Visual Question Answering (VQACL) requires models to acquire new visual-linguistic skills (plasticity) while preserving previously learned knowledge (stability). The inherent multimodality of VQACL exacerbates this challenge, as models must balance stability across visual and textual domains while adapting to novel objects and reasoning tasks. Existing methods, primarily designed for unimodal settings, often fall short in addressing this dual requirement. In this work, we present QUestion-only replay with Attention Distillation (QUAD), a novel approach for VQACL that leverages only past task questions for regularization. By eliminating the need to store visual data, QUAD not only reduces memory overhead, but also alleviates privacy concerns. Our method introduces a Question-only Replay mechanism that selectively reuses prior task questions to counteract overfitting to the answer space of the current task, addressing the problem out of answer set. Complementing this, we propose Attention Consistency Distillation to enforce both intra-modal and inter-modal attention consistency across tasks, preserving essential visual-linguistic associations. Extensive experiments on VQAv2 and NExT-QA demonstrate that QUAD significantly outperforms state-of-the-art methods, achieving robust performance in continual VQA.},
  html={https://arxiv.org/abs/2502.04469},
  pdf={https://arxiv.org/pdf/2502.04469.pdf},
  selected={true},
  bibtex_show={true}
}

@inproceedings{marouf2025plastic,
  title={Enhancing Plasticity for First Session Adaptation Continual Learning},
  author={Marouf, Imad Eddine and Roy, Subhankar and Lathuiliere, Stephane and Tartaglione, Enzo},
  booktitle={Conference on Lifelong Learning Agents (CoLLAs)},
  year={2025},
  abbr={CoLLAs},
  arxiv={2310.11482},
  code={https://github.com/IemProg/PLASTIC},
  abstract={The integration of large pre-trained models (PTMs) into Class-Incremental Learning (CIL) has facilitated the development of compute-efficient strategies such as First-Session Adaptation (FSA), which fine-tunes the model solely on the first task while keeping it frozen for subsequent tasks. Although effective in homogeneous task sequences, these approaches struggle when faced with the heterogeneity of real-world task distributions. We introduce PLASTIC (Plasticity-Enhanced Test-Time Adaptation in Class-Incremental Learning), a method that reinstates plasticity in CIL while preserving model stability. PLASTIC leverages test-time adaptation to dynamically adjust model parameters during inference, enabling continued learning without catastrophic forgetting. Our comprehensive experiments demonstrate that PLASTIC significantly outperforms existing first-session adaptation methods across various continual learning benchmarks, achieving robust performance while maintaining computational efficiency.},
  html={https://arxiv.org/abs/2310.11482},
  pdf={https://arxiv.org/pdf/2310.11482.pdf},
  selected={true},
  bibtex_show={true}
}